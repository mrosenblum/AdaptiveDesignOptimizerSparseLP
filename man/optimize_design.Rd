% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimize_design.R
\name{optimize_design}
\alias{optimize_design}
\title{Adaptive Enrichment Design Optimization Using Sparse Linear Programming}
\usage{
optimize_design(
  subpopulation.1.proportion,
  total.alpha,
  data.generating.distributions,
  stage.1.sample.sizes,
  stage.2.sample.sizes.per.enrollment.choice,
  objective.function.weights,
  power.constraints,
  type.of.LP.solver = "cplex",
  discretization.parameter = c(1, 1, 10),
  number.cores = 30,
  ncp.list = c(),
  list.of.rectangles.dec = c(),
  LP.iteration = 1,
  prior.covariance.matrix = diag(2) * 0,
  LP.solver.path = c(),
  loss.function = c(),
  cleanup.temporary.files = TRUE
)
}
\arguments{
\item{subpopulation.1.proportion}{Proportion of overall population in subpopulation 1. Must be between 0 and 1.}

\item{total.alpha}{Familywise Type I error rate (1-sided)}

\item{data.generating.distributions}{Matrix encoding data generating distributions (defined in terms of treatment effect pairs and outcome variances) used to define power constraints and  objective function; each row defines the pair (Delta_1,Delta_2) of subpopulation 1 and 2 average treatment effects, followed by outcome variances for the four combinations of subpouplation (1 and 2) by study arm (0 and 1).}

\item{stage.1.sample.sizes}{Vector with 2 entries representing stage 1 sample sizes for subpopulations 1 and 2, respectively}

\item{stage.2.sample.sizes.per.enrollment.choice}{Matrix with number.choices.end.of.stage.1 rows and 2 columns, where the (i,j) entry represents the stage 2 sample size under enrollment choice i for subpopulation j.}

\item{objective.function.weights}{Vector with length equal to number of rows of population.parameters, representing weights used to define the objective function}

\item{power.constraints}{Matrix with same number of rows as population.parameters (each representing a data generating distribution) and three columns corresponding to the required power to reject (at least) H_01, H_02, H_0C, respectively.}

\item{type.of.LP.solver}{"matlab", "cplex", "GLPK", or "gurobi" The linear program solve that you want to use; assumes that you have installed this already and that path is set}

\item{discretization.parameter}{vector with 3 positive-valued components representing initial discretization of decision region, rejection regions, and grid representing Type I error constraints; first component is edge length of each square in the decision region, second component is edge length of each square in the rejection regions, and third component determines the number of Type I error constraints equally spaced on the boundary of the null space for each null hypothesis. The third component is only used if ncp.list below is left unspecified.}

\item{number.cores}{the number of cores available for parallelization using the parallel R package}

\item{ncp.list}{list of pairs of real numbers representing the non-centrality parameters to be used in the Type I error constraints; if list is empty, then default list is used.}

\item{list.of.rectangles.dec}{list of rectangles representing decision region partition, encoded as a list with each element of the list having fields $lower_boundaries (pair of real numbers representing coordinates of lower left corner of rectangle), $upper_boundaries (pair of real numbers representing upper right corner of rectangle), $allowed_decisions (subset of stage.2.sample.sizes.per.enrollment.choice representing which decisions allowed if first stage z-statistics are in corresponding rectangle; default is entire list stage.2.sample.sizes.per.enrollment.choice), $preset_decision (indicator of whether the decision probabilities are hard-coded by the user; default is 0), $d_probs (empty unless $preset_decision==1, in which case it is a vector representing the probabilities of each decision); if list.or.rectangles.dec is empty, then a default partition is used based on discretization.parameter.}

\item{LP.iteration}{positive integer used in file name to store output; can be used to avoid overwriting previous computations}

\item{prior.covariance.matrix}{2x2 positive semidefinite matrix representing the covariance corresponding to each component of the mixture of multivariate normals prior distribution (used only in defining the objective function); the default is the matrix of all 0's, corresponding to the prior being a mixture of point masses. If separate covariance matrices are desired for each component of the mixture prior distribution, a list of  such 2x2 matrices of same length as the number of rows in data.generating.distributions can be provided instead of a single matrix; this option allows the user to specify anyfinite mixture of point masses (by setting the corresponding covariance matrices to have all 0's) and bivariate normal distributions.}

\item{LP.solver.path}{path (i.e., directory) where LP.solver is installed; e.g., if type.of.LP.solver=="cplex" then LP.solver.path is directory where cplex is installed}

\item{loss.function}{a matrix of same length as the number of enrollment choices for stage 2, i.e., same length as the number of rows in stage.2.sample.sizes.per.enrollment.choice. Each component d of this vector represents the loss corresponding to enrollment choice d; if nothing is specified, the default is to use the total sample size under each enrollment choice, so that the objective function represents expected sample size. An alternative choice would be, for example, the trial duration under each enrollment choice, or some combination of sample size and trial duration.}

\item{cleanup.temporary.files}{TRUE/FALSE indicates whether temporary files generated during problem solving process should be deleted or not after termination; set to FALSE for debugging purposes only.}
}
\value{
An optimized policy is returned, consisting of the following elements (defined in the paper): S1, A1, S2, A2 (sets of states and actions) and the optimized policy (pi_1, pi_2). Also, additional information related to the optimized design is saved as "optimized_design<k>.rdata", where <k> is the user-defined iteration number (LP.iteration).
}
\description{
Adaptive Enrichment Design Optimization Using Sparse Linear Programming
}
\note{
See inst/examples/example3.2reduced which is a simplified example
that can be run in 10 minutes using the GLPK solver, which
involves solving a modified version of the problem from Example
3.2 as described in Section 5.2 of the manuscript; the main
modifications are that we  use a coarsened partition of the
decision region and rejection regions in order to speed up the
computation.
}
\section{Output}{

The software computes an optimized design and saves it as "optimized_design<k>.rdata", where <k> is the user-defined iteration number (LP.iteration). E.g., if one sets LP.iteration=1, then the optimized design is saved as "optimized_design1.rdata". That file can be opened in R and contains the following 6 items:
input.parameters (the inputs passed to the optimized_design function)
list.of.rectangles.dec (the decision rectangle partition of R^2)
list.of.rectangles.mtp (the multiple testing procedure partition of R^2)
ncp.active.FWER.constraints (the active familywise Type I error constraints in the optimized design, obtained using the dual solution to the linear program)
ncp.list (the complete list of familywise Type I error constraints input to the linear program solver)
sln (the solution to the linear program; sln$val is the expected sample size; sln$status, if either 1 or 5, indicates that a feasible solution was found and other wise the problem was infeasible or no solution was found; sln$z is the actual solution as a vector)
}

\examples{
library(AdaptiveDesignOptimizerSparseLP)
#Install R package if not already done so using the following command:
#remotes::install_github("mrosenblum/AdaptiveDesignOptimizerSparseLP")
# Load R package if not already done so by the following command: library(AdaptiveDesignOptimizerSparseLP)
# For reproducibility, set the random number generator seed:
set.seed(32515)

# Set all problem parameters based on Example 3.2, and using explicit choices of the following input parameters:
# The proportion of the population in subpopulation 1:
subpopulation.1.proportion = 0.5

# Sample sizes
# Sample size in stage 1 for each subpopulation: 50;
stage.1.sample.sizes = c(50, 50)

# We set n=200 in our adaptive design template n^(1b), which corresponds to the following four
# choices for stage 2 enrollment:
stage.2.sample.sizes.per.enrollment.choice = matrix(
  c(50, 50,  # Stage 2: enroll 50 from each subpopulation
    0, 0,   # Stop trial after stage 1
    150, 0, # Stage 2: enroll 150 from subpopulation 1 and none from subpopulation 2
    0, 150),
  # Stage 2: enroll none from subpopulation 1 and 150 from subpopulation 2
  nrow = 4,
  ncol = 2,
  byrow = TRUE,
  dimnames = list(
    c(),
    c(
      "Subpopulation1Stage2SampleSize",
      "Subpopulation2Stage2SampleSize"
    )
  )
)

# Set the Minimum, clinically meaningful treatment effect size, which we set slightly larger than
# in examples in Section 5.2 for illustration purposes (since our coarsened decision and rejection regions in the illustration here require this for the problem to be feasible):
Delta_min = 1.2 * sqrt(1 / 2) * (qnorm(0.95 + 1e-4) + qnorm(0.95)) / 5

# The data generating distributions for Example 3.2 are encoded as follows
# (where we set the outcome variance to 1 for each subpopulation bby study arm combination):
# The first 2 entries in each row represent \Delta_1 and \Delta_2
data.generating.distributions = matrix(
  data = c(
    0,
    0,
    1,
    1,
    1,
    1,
    # zero treatment effect in each arm
    0,
    Delta_min,
    1,
    1,
    1,
    1,
    # Delta_min treatment effect subpopulation 2, no effect subpopulation 1
    Delta_min,
    0,
    1,
    1,
    1,
    1,
    # Delta_min treatment effect subpopulation 1, no effect subpopulation 2
    Delta_min,
    Delta_min,
    1,
    1,
    1,
    1
  ),
  # Delta_min treatment effect each subpopulation
  nrow = 4,
  ncol = 6,
  byrow = TRUE,
  dimnames = list(
    c(),
    c(
      "Delta1",
      "Delta2",
      "Variance10",
      "Variance11",
      "Variance20",
      "Variance21"
    )
  )
)

# The resulting non-centrality parameter (see Section 5.1 of the paper) matches that used in the paper computations.
# Required Familywise Type I error:
total.alpha = 0.05

desired.power = 0.8

power.constraints = matrix(
  c(
    0,
    0,
    0,
    # No power requirements under first data generating distribution
    0,
    desired.power,
    0,
    # 80\% power required for rejecting H02 under 2nd data generating distribution
    desired.power,
    0,
    0,
    # 80\% power required for rejecting H01 under 3nd data generating distribution
    0,
    0,
    desired.power
  ),
  # 80\% power required for rejecting H0C under 4th data generating distribution
  nrow = 4,
  ncol = 3,
  byrow = TRUE,
  dimnames = list(c(), c("PowerH01", "PowerH02", "PowerH0C"))
)

objective.function.weights = 0.25 * c(1, 1, 1, 1)
# Equal weights on each data generating distribution
prior.covariance.matrix = diag(2)
# Prior distribution \Lambda is mixture of 4 point bivariate normal distributions with identity covariance matrix and means given by first 2 columns in data.generating.distributions
type.of.LP.solver = "glpk"

discretization.parameter = c(3, 3, 1)

number.cores = min(parallel::detectCores(), 4)


# Run first iteration solving sparse linear program
optimized.policy <- optimize_design(
  subpopulation.1.proportion,
  total.alpha,
  data.generating.distributions,
  stage.1.sample.sizes,
  stage.2.sample.sizes.per.enrollment.choice,
  objective.function.weights,
  power.constraints,
  type.of.LP.solver,
  discretization.parameter,
  number.cores,
  prior.covariance.matrix = prior.covariance.matrix
)
}
\author{
Michael Rosenblum, Ethan Fang, Han Liu
}
